proxy:
  target_url: "https://llm.chutes.ai/v1"
  api_key: "api-key"
  provider: ""
  timeout: 30
  debug_mode: false
  allow_extra_params: true

scenario:
  file_path: "./scenarios/scenario.json"
  output_format: "json"
  clear_strategy: "always"
  similarity_threshold: 0.9

langgraph:
  max_history_length: 7
  last_ai_messages_index: -1
  ai_message_min_length: 200
  only_forward: false
  stream_workflow_to_frontend: true

agent:
  model: "Qwen/Qwen3-235B-A22B-Instruct-2507"
  temperature: 0
  base_url: "https://llm.chutes.ai/v1" 
  api_key: "api-key"
  provider: ""
  max_tokens: 8192
  top_p: 0.9
  debug: false
  max_iterations: 40
  stream_mode: true
  workflow_mode: "fast"
  timeout: 120
  enable_wiki_search: false
  external_knowledge_path: "" 


server:
  host: "0.0.0.0"
  port: 6666
  reload: false

comfyui:
  enabled: false
  comfy_url: "http://<cpmfyui-ip>:8188"
  api_key: "api-key"
  workflow_path: "3rd/comfyui/wai.json"
  positive_prompt_node_id: "6"
  latent_image_node_id: "5"
  width: 960
  height: 1024
  num_images: 3
  positive_prefix: "masterpiece,best quality,amazing quality,"
  max_display_size: 480

log:
  base_log_path: "./logs"
  enable_agent_history: true
  history_format: "txt"
  save_request_origin_messages: true
