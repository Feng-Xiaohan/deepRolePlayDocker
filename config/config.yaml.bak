# ====================================================================
# DeepRolePlay Configuration File - Beginner's Guide
# ====================================================================
# 
# ü§î What are "Forwarding LLM" and "Agent LLM"?
# 
# „ÄêForwarding LLM„Äë= The AI model you actually want to chat with
# ‚Ä¢ This is the AI that ultimately chats with users, like DeepSeek, Claude, GPT, etc.
# ‚Ä¢ The API Key you fill in SillyTavern is for this model
# ‚Ä¢ Configuration location: proxy section below
# 
# „ÄêAgent LLM„Äë= Behind-the-scenes intelligent assistant AI model  
# ‚Ä¢ Responsible for "memory flashback" and "scenario update", users don't see its responses
# ‚Ä¢ Recommend using cheap and fast models, like Gemini 2.5 Flash (large free quota)
# ‚Ä¢ Configuration location: agent section below
# 
# üí° Example:
# - Forwarding LLM: DeepSeek (cheap, chats with users) ‚Üí fill base_url in proxy section, api_key and other configs in your frontend. Frontend should use base_url: http://localhost:6666/api/v1
# - Agent LLM: Gemini (free, background work) ‚Üí fill in agent section
# - You need two different API Keys!
# 
# üîó Data flow: User ‚Üí DeepRolePlay ‚Üí Agent LLM processes memory ‚Üí Forwarding LLM generates response
# ====================================================================

# „ÄêAPI Proxy Configuration„ÄëForward to target LLM service
proxy:
  # Target LLM service address | Controls request forwarding destination | Need to change: Fill in your LLM service API address
  target_url: "https://api.deepseek.com/v1"
  # HTTP request timeout (seconds) | Controls request wait duration | Usually no need to change: 30 seconds is sufficient
  timeout: 30
  # Debug mode switch | Controls whether to skip workflow and return test message directly | Usually no need to change: false for normal operation
  debug_mode: false

# „ÄêScenario File Configuration„ÄëCharacter state storage
scenario:
  # Scenario file storage path | Controls character state save location | Usually no need to change: auto-creates directory
  file_path: "./scenarios/scenario.txt"

# „ÄêWorkflow Control Configuration„ÄëAgent execution parameters
langgraph:
  # Number of history messages passed to Agent | Controls context length and token consumption | Adjustable: 3-15 messages, affects memory effectiveness and cost
  max_history_length: 7
  # History message starting offset | Controls message calculation starting point | Usually no need to change: technical parameter
  history_ai_message_offset: 1
  # Fast forward mode | Controls whether to skip Agent and forward directly | Usually no need to change: false for normal operation
  only_forward: false

# „ÄêAgent Configuration„ÄëAI model for memory flashback and scenario update
agent:
  # AI model name | Controls which AI model to use | Recommended adjustment: google/gemini-2.5-flash
  model: "google/gemini-2.5-flash"
  # Generation randomness (0-1) | Controls answer creativity | Adjustable: 0.1 stable, 0.7 creative, affects consistency
  temperature: 0.1
  # API service provider address | Controls model call interface | Need to change: choose corresponding service provider based on model
  base_url: "https://openrouter.ai/api/v1"
  # API access key | Controls service authentication | Must change: fill in valid key from corresponding service provider
  api_key: "Replace this with your API key"
  # Maximum output tokens | Controls single generation length limit | Usually no need to change: 8192 sufficient for most scenarios
  max_tokens: 8192
  # Sampling probability threshold (0-1) | Controls vocabulary selection range | Usually no need to change: 0.9 ensures diversity
  top_p: 0.9
  # Agent debug information | Controls whether to show detailed execution process | Change when debugging: true shows process, false for normal operation
  debug: false
  # Maximum execution rounds | Controls upper limit to prevent infinite loops | Usually no need to change: 40 rounds sufficient for complex tasks
  max_iterations: 40
  # Single request timeout (seconds) | Controls Agent call wait duration | Adjustable: increase to 180 for slow networks
  timeout: 120

# „ÄêServer Configuration„ÄëDeepRolePlay service network settings
server:
  # Listen IP address | Controls external access permissions | Usually no need to change: 0.0.0.0 allows LAN access
  host: "0.0.0.0"
  # Service port number | Controls frontend connection port | Adjustable: auto-increments if occupied, frontend needs corresponding modification
  port: 6666
  # Code hot reload | Controls automatic restart during development | Usually no need to change: false avoids accidental restarts in production
  reload: false